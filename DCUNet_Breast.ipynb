{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZgOt7jpMrm5",
        "outputId": "fe82960b-c70c-4625-84d1-1a853a205bee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import initializers\n",
        "from keras.layers import SpatialDropout2D,Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate,AveragePooling2D, UpSampling2D, BatchNormalization, Activation, add,Dropout,Permute,ZeroPadding2D,Add, Reshape\n",
        "from keras.models import Model, model_from_json\n",
        "from keras.optimizers import Adam\n",
        "# from keras.layers.advanced_activations import ELU, LeakyReLU, ReLU, PReLU\n",
        "# from keras.utils.vis_utils import plot_model\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import classification_report\n",
        "from keras import applications, optimizers, callbacks\n",
        "from tensorflow.keras.metrics import MeanIoU, Recall, Precision, BinaryAccuracy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.layers import *\n",
        "import json\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "YDxZCIMTM-rK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correct recall for tf\n",
        "def recall_tf(y_true, y_pred):\n",
        "    Y_true = tf.dtypes.cast(y_true, tf.float32)\n",
        "    Y_true = K.flatten(Y_true)\n",
        "    Y_pred = tf.dtypes.cast(tf.math.greater(y_pred, 0.5), tf.float32)\n",
        "    Y_pred = K.flatten(Y_pred)\n",
        "\n",
        "    true_positives = tf.reduce_sum(Y_true * Y_pred)\n",
        "    possible_positives = tf.reduce_sum(Y_true)\n",
        "    recall = true_positives / (possible_positives + tf.keras.backend.epsilon())\n",
        "    return recall"
      ],
      "metadata": {
        "id": "JLP5JLBEC1Qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correct tf precision\n",
        "def precision_tf(y_true, y_pred):\n",
        "    Y_true = tf.dtypes.cast(y_true, tf.float32)\n",
        "    Y_true = K.flatten(Y_true)\n",
        "    Y_pred = tf.dtypes.cast(tf.math.greater(y_pred, 0.5), tf.float32)\n",
        "    Y_pred = K.flatten(Y_pred)\n",
        "\n",
        "    true_positives = tf.reduce_sum(tf.round(tf.clip_by_value(Y_true * Y_pred, 0, 1)))\n",
        "    print(true_positives)\n",
        "    predicted_positives = tf.reduce_sum(tf.round(tf.clip_by_value(Y_pred, 0, 1)))\n",
        "    print(predicted_positives)\n",
        "    precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n",
        "    return precision"
      ],
      "metadata": {
        "id": "pkSEkRSqC1rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correct tf dicecoefficient\n",
        "def dice_coefficient_tf(y_true, y_pred):\n",
        "    Y_true = tf.dtypes.cast(y_true, tf.float32)\n",
        "    Y_true = K.flatten(Y_true)\n",
        "    Y_pred = tf.dtypes.cast(tf.math.greater(y_pred, 0.5), tf.float32)\n",
        "    Y_pred = K.flatten(Y_pred)\n",
        "\n",
        "    smooth = 1e-5\n",
        "\n",
        "    intersection = tf.reduce_sum(Y_true * Y_pred)\n",
        "    union = tf.reduce_sum(Y_true) + tf.reduce_sum(Y_pred)\n",
        "    return (2.0 * intersection + smooth) / (union + smooth)\n"
      ],
      "metadata": {
        "id": "a3MShvBeC3fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coefficient_for_loss(y_true, y_pred):\n",
        "    Y_true = tf.dtypes.cast(y_true, tf.float32)\n",
        "    Y_true = K.flatten(Y_true)\n",
        "\n",
        "    Y_pred = K.flatten(y_pred)\n",
        "\n",
        "    smooth = 1e-5\n",
        "\n",
        "    intersection = K.sum(Y_true * Y_pred)\n",
        "\n",
        "    union = K.sum(Y_true) + K.sum(Y_pred)\n",
        "    return (2.0 * intersection + smooth) / (union + smooth)\n"
      ],
      "metadata": {
        "id": "qeF_YhjetVe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef_loss(y_true, y_pred):\n",
        "    loss = - dice_coefficient_for_loss(y_true, y_pred)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "fYdwyTdG-wak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bce_dice_loss(y_true, y_pred):\n",
        "    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
        "    dice = 1 - dice_coefficient_for_loss(y_true, y_pred)\n",
        "    return bce + dice"
      ],
      "metadata": {
        "id": "CXFFPtOBByTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), activation='relu', name=None):\n",
        "    '''\n",
        "    2D Convolutional layers\n",
        "\n",
        "    Arguments:\n",
        "        x {keras layer} -- input layer\n",
        "        filters {int} -- number of filters\n",
        "        num_row {int} -- number of rows in filters\n",
        "        num_col {int} -- number of columns in filters\n",
        "\n",
        "    Keyword Arguments:\n",
        "        padding {str} -- mode of padding (default: {'same'})\n",
        "        strides {tuple} -- stride of convolution operation (default: {(1, 1)})\n",
        "        activation {str} -- activation function (default: {'relu'})\n",
        "        name {str} -- name of the layer (default: {None})\n",
        "\n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False)(x)\n",
        "    x = BatchNormalization(axis=3, scale=False)(x)\n",
        "\n",
        "    if(activation == None):\n",
        "        return x\n",
        "\n",
        "    x = Activation(activation, name=name)(x)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "6bS0lFvPNCbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trans_conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(2, 2), name=None):\n",
        "    '''\n",
        "    2D Transposed Convolutional layers\n",
        "\n",
        "    Arguments:\n",
        "        x {keras layer} -- input layer\n",
        "        filters {int} -- number of filters\n",
        "        num_row {int} -- number of rows in filters\n",
        "        num_col {int} -- number of columns in filters\n",
        "\n",
        "    Keyword Arguments:\n",
        "        padding {str} -- mode of padding (default: {'same'})\n",
        "        strides {tuple} -- stride of convolution operation (default: {(2, 2)})\n",
        "        name {str} -- name of the layer (default: {None})\n",
        "\n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "    x = Conv2DTranspose(filters, (num_row, num_col), strides=strides, padding=padding)(x)\n",
        "    x = BatchNormalization(axis=3, scale=False)(x)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "UPzNKq7iNTTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DCBlock(U, inp, alpha = 1.67):\n",
        "    '''\n",
        "    DC Block\n",
        "\n",
        "    Arguments:\n",
        "        U {int} -- Number of filters in a corrsponding UNet stage\n",
        "        inp {keras layer} -- input layer\n",
        "\n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "    W = alpha * U\n",
        "\n",
        "    conv3x3_1 = conv2d_bn(inp, int(W*0.167), 3, 3,\n",
        "                        activation='relu', padding='same')\n",
        "\n",
        "    conv5x5_1 = conv2d_bn(conv3x3_1, int(W*0.333), 3, 3,\n",
        "                        activation='relu', padding='same')\n",
        "\n",
        "    conv7x7_1 = conv2d_bn(conv5x5_1, int(W*0.5), 3, 3,\n",
        "                        activation='relu', padding='same')\n",
        "\n",
        "    out1 = concatenate([conv3x3_1, conv5x5_1, conv7x7_1], axis=3)\n",
        "    out1 = BatchNormalization(axis=3)(out1)\n",
        "\n",
        "    conv3x3_2 = conv2d_bn(inp, int(W*0.167), 3, 3,\n",
        "                        activation='relu', padding='same')\n",
        "\n",
        "    conv5x5_2 = conv2d_bn(conv3x3_2, int(W*0.333), 3, 3,\n",
        "                        activation='relu', padding='same')\n",
        "\n",
        "    conv7x7_2 = conv2d_bn(conv5x5_2, int(W*0.5), 3, 3,\n",
        "                        activation='relu', padding='same')\n",
        "    out2 = concatenate([conv3x3_2, conv5x5_2, conv7x7_2], axis=3)\n",
        "    out2 = BatchNormalization(axis=3)(out2)\n",
        "\n",
        "    out = add([out1, out2])\n",
        "    out = Activation('relu')(out)\n",
        "    out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "E95vSUP2NVAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResPath(filters, length, inp):\n",
        "    '''\n",
        "    ResPath\n",
        "    Arguments:\n",
        "        filters {int} -- [description]\n",
        "        length {int} -- length of ResPath\n",
        "        inp {keras layer} -- input layer\n",
        "\n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "    shortcut = inp\n",
        "    shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
        "                          activation=None, padding='same')\n",
        "\n",
        "    out = conv2d_bn(inp, filters, 3, 3, activation='relu', padding='same')\n",
        "\n",
        "    out = add([shortcut, out])\n",
        "    out = Activation('relu')(out)\n",
        "    out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    for i in range(length-1):\n",
        "\n",
        "        shortcut = out\n",
        "        shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
        "                              activation=None, padding='same')\n",
        "\n",
        "        out = conv2d_bn(out, filters, 3, 3, activation='relu', padding='same')\n",
        "\n",
        "        out = add([shortcut, out])\n",
        "        out = Activation('relu')(out)\n",
        "        out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "6WLny9kfNXbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1G_JKK6TbZIp"
      },
      "outputs": [],
      "source": [
        "# def DCUNet(height, width, channels):\n",
        "    '''\n",
        "    DC-UNet\n",
        "\n",
        "    Arguments:\n",
        "        height {int} -- height of image\n",
        "        width {int} -- width of image\n",
        "        n_channels {int} -- number of channels in image\n",
        "\n",
        "    Returns:\n",
        "        [keras model] -- MultiResUNet model\n",
        "    '''\n",
        "X_train = np.load('/content/drive/MyDrive/Dataset/Breast_Dataset_Final/X_train.npy')\n",
        "Y_train = np.load('/content/drive/MyDrive/Dataset/Breast_Dataset_Final/Y_train.npy')\n",
        "\n",
        "IMG_HEIGHT = 128\n",
        "IMG_WIDTH = 128\n",
        "IMG_CHANNELS = 1\n",
        "learning_rate = 0.001\n",
        "\n",
        "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "\n",
        "dcblock1 = DCBlock(32, inputs)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(dcblock1)\n",
        "dcblock1 = ResPath(32, 4, dcblock1)\n",
        "\n",
        "dcblock2 = DCBlock(32*2, pool1)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(dcblock2)\n",
        "dcblock2 = ResPath(32*2, 3, dcblock2)\n",
        "\n",
        "dcblock3 = DCBlock(32*4, pool2)\n",
        "pool3 = MaxPooling2D(pool_size=(2, 2))(dcblock3)\n",
        "dcblock3 = ResPath(32*4, 2, dcblock3)\n",
        "\n",
        "dcblock4 = DCBlock(32*8, pool3)\n",
        "pool4 = MaxPooling2D(pool_size=(2, 2))(dcblock4)\n",
        "dcblock4 = ResPath(32*8, 1, dcblock4)\n",
        "\n",
        "dcblock5 = DCBlock(32*16, pool4)\n",
        "\n",
        "up6 = concatenate([Conv2DTranspose(\n",
        "    32*8, (2, 2), strides=(2, 2), padding='same')(dcblock5), dcblock4], axis=3)\n",
        "dcblock6 = DCBlock(32*8, up6)\n",
        "\n",
        "up7 = concatenate([Conv2DTranspose(\n",
        "    32*4, (2, 2), strides=(2, 2), padding='same')(dcblock6), dcblock3], axis=3)\n",
        "dcblock7 = DCBlock(32*4, up7)\n",
        "\n",
        "up8 = concatenate([Conv2DTranspose(\n",
        "    32*2, (2, 2), strides=(2, 2), padding='same')(dcblock7), dcblock2], axis=3)\n",
        "dcblock8 = DCBlock(32*2, up8)\n",
        "\n",
        "up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(\n",
        "    2, 2), padding='same')(dcblock8), dcblock1], axis=3)\n",
        "dcblock9 = DCBlock(32, up9)\n",
        "\n",
        "conv10 = conv2d_bn(dcblock9, 1, 1, 1, activation='sigmoid')\n",
        "\n",
        "model = Model(inputs=[inputs], outputs=[conv10])\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer= Adam(learning_rate),\n",
        "    loss= 'binary_crossentropy',\n",
        "    metrics=[\n",
        "        BinaryAccuracy(name='accuracy'),  # Binary Accuracy\n",
        "        MeanIoU(num_classes=2, name='iou'),  # Intersection Over Union (IoU)\n",
        "        recall_tf,  # Sensitivity\n",
        "        precision_tf,\n",
        "         tf.keras.metrics.BinaryIoU(\n",
        "            threshold=0.5,\n",
        "            name='binaryIoU',\n",
        "            dtype=None\n",
        "        ),\n",
        "        Recall(name='recall_inbuilt'),\n",
        "        Precision(name='precision_inbuilt'),\n",
        "        dice_coefficient_tf  # Custom dice coefficient function\n",
        "    ]\n",
        ")\n",
        "\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/Project7thSem/Breast_Dataset_Final/DCUNet/Binary/model_for_breast.h5', verbose=1, save_best_only=True)\n",
        "\n",
        "\n",
        "callbacks = [\n",
        "              tf.keras.callbacks.TensorBoard(log_dir = '/content/drive/MyDrive/Project7thSem/Breast_Dataset_Final/DCUNet/Binary'),\n",
        "              checkpointer\n",
        "]\n",
        "\n",
        "# Saving the accuracy as the model gets trained\n",
        "\n",
        "results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=50, callbacks=callbacks)\n",
        "model.save('/content/drive/MyDrive/Project7thSem/Breast_Dataset_Final/DCUNet/Binary/dcunet_model.h5')\n",
        "\n",
        "\n",
        "# Saving the data\n",
        "with open('/content/drive/MyDrive/Project7thSem/Breast_Dataset_Final/DCUNet/Binary/training_history128.json', 'w') as file:\n",
        "     json.dump(results.history, file)\n"
      ]
    }
  ]
}